{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "qnZi6QpwH1Zz"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2--EYFPLHpvu",
        "colab_type": "text"
      },
      "source": [
        "### Project"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "MIFkdIvmgZwu",
        "colab": {}
      },
      "source": [
        "# Import section\n",
        "import torch as torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qnZi6QpwH1Zz",
        "colab_type": "text"
      },
      "source": [
        "##### Defining values of batch size and defining transformations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D0v3JqRJgoRq",
        "colab": {}
      },
      "source": [
        "batch_size = 64\n",
        "test_batch_size = 64\n",
        "mnist_batch_size = 64\n",
        "train_batch_size=64\n",
        "torch.manual_seed(7)\n",
        "np.random.seed(7)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "\n",
        "# Transformations\n",
        "data_transformations = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "test_transformations = transforms.Compose([\n",
        "\n",
        "    transforms.Grayscale(3),\n",
        "    transforms.transforms.Resize((32, 32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVAxeFeaH-Jo",
        "colab_type": "text"
      },
      "source": [
        "##### Load Data, create data loaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fdVpJrDBgod2",
        "outputId": "6dbe7727-113e-4384-85a2-668f99fcd1b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "# Data Source\n",
        "mnist_train = datasets.MNIST('../data', train=True, download=True,\n",
        "                                 transform=test_transformations)\n",
        "mnist_test = datasets.MNIST('../data', train=False, download=True,\n",
        "                                transform=test_transformations)\n",
        "svhn_train = datasets.SVHN('../data', split='train', download=True,\n",
        "                               transform=data_transformations)\n",
        "svhn_test = datasets.SVHN('../data', split='test', download=True,\n",
        "                              transform=data_transformations)\n",
        "\n",
        "# Data loaders\n",
        "train_loader = DataLoader(svhn_train,\n",
        "                          batch_size=batch_size, shuffle=True)\n",
        "\n",
        "mnist_test_loader = DataLoader(mnist_test,\n",
        "                          batch_size=mnist_batch_size, shuffle=True)\n",
        "svhn_test_loader = DataLoader(svhn_test,\n",
        "                          batch_size=mnist_batch_size, shuffle=True)\n",
        "svhn_train_loader = DataLoader(svhn_train,\n",
        "                          batch_size=mnist_batch_size, shuffle=True)\n",
        "\n",
        "mnist_train_loader = DataLoader(mnist_train,\n",
        "                          batch_size=mnist_batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9912422 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "9920512it [00:00, 20355842.93it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 312100.23it/s]                           \n",
            "0it [00:00, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1654784it [00:00, 5133166.35it/s]                           \n",
            "8192it [00:00, 127241.80it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
            "Processing...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/182040794 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Done!\n",
            "Downloading http://ufldl.stanford.edu/housenumbers/train_32x32.mat to ../data/train_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "182042624it [00:06, 29625166.90it/s]                               \n",
            "  0%|          | 16384/64275384 [00:00<08:30, 125804.78it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://ufldl.stanford.edu/housenumbers/test_32x32.mat to ../data/test_32x32.mat\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "64282624it [00:04, 14694639.06it/s]                              \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJvY4muIIFR5",
        "colab_type": "text"
      },
      "source": [
        "###### Xavier weight initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vr4PW5k0oBP2",
        "colab": {}
      },
      "source": [
        "def init_weights(m):\n",
        "    if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
        "      torch.nn.init.xavier_uniform(m.weight)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ck2qZbHIJfZ",
        "colab_type": "text"
      },
      "source": [
        "#### Model definining section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TS1UzzZHINNY",
        "colab_type": "text"
      },
      "source": [
        "###### Feature Extractor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wHgI2N91gog4",
        "colab": {}
      },
      "source": [
        "class FeatureExtractor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(FeatureExtractor, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "                        nn.Conv2d(3,64,5,padding=1),   # batch x 16 x 28 x 28\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(3, stride=2),\n",
        "                        nn.Conv2d(64,64,5,padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(3, stride=2),\n",
        "                        nn.Conv2d(64,128,5,padding=1),\n",
        "                        nn.ReLU(),\n",
        "                        nn.MaxPool2d(3, stride=2),\n",
        "                        )\n",
        "    self.layer1.apply(init_weights)\n",
        "  def forward(self, x):\n",
        "    out = self.layer1(x)\n",
        "    return out.view(x.size()[0], -1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKLq-hUQIU8F",
        "colab_type": "text"
      },
      "source": [
        "###### Defining Gradient Reversal Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mLO5BUJ24AJo",
        "colab": {}
      },
      "source": [
        "class GradRevLayer(torch.autograd.Function):\n",
        "  lambd = 1.0\n",
        "  @staticmethod\n",
        "  def forward(ctx,x):\n",
        "    return x.view_as(x)\n",
        "  \n",
        "  @staticmethod\n",
        "  def backward(ctx, out_grads):\n",
        "    return GradRevLayer.lambd * out_grads.neg()\n",
        "  \n",
        "\n",
        "def grad_reverse_layer(x, new_lambd):\n",
        "    GradRevLayer.lambd = new_lambd\n",
        "    return GradRevLayer.apply(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "UZWiqW04rM7q"
      },
      "source": [
        "##### Domain Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KkHMxzgJlF5M",
        "colab": {}
      },
      "source": [
        "class DomainClassifier(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(DomainClassifier, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(128, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 1024),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(1024, 2),\n",
        "        nn.LogSigmoid()\n",
        "    )\n",
        "    self.layer1.apply(init_weights)\n",
        "  def forward(self, x):\n",
        "    x = grad_reverse_layer(x,self.lambd)\n",
        "    return self.layer1(x)\n",
        "  def set_lambda(self, lambd):\n",
        "    self.lambd = lambd\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "2P7tAPOorITL"
      },
      "source": [
        "##### LabelPredictor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WuozHtgkgoj_",
        "colab": {}
      },
      "source": [
        "class LabelPredictor(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(LabelPredictor, self).__init__()\n",
        "    self.layer1 = nn.Sequential(\n",
        "        nn.Linear(128, 3072),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(3072, 2048),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(2048, 10),\n",
        "        nn.LogSoftmax()\n",
        "    )\n",
        "    self.layer1.apply(init_weights)\n",
        "  def forward(self, x):\n",
        "    return self.layer1(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "yrGLW7J0gomu"
      },
      "source": [
        "##### Create dataset for domainclasiifier\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6CfEPLTBurm6",
        "colab": {}
      },
      "source": [
        "X_mnist = []\n",
        "for i in range(len(mnist_train)):\n",
        "  X_mnist.append(mnist_train.__getitem__(i)[0])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1e4OLfLDLfUV",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vc8TV91etmip",
        "colab": {}
      },
      "source": [
        "X_mnist_tensor = torch.stack(X_mnist)\n",
        "y_mnist = torch.zeros(len(X_mnist))\n",
        "X_svhn = torch.tensor(svhn_train.data[:len(X_mnist)])\n",
        "y_svhn = torch.ones(len(X_svhn))\n",
        "X = torch.cat((X_mnist_tensor.float(),X_svhn.float()))\n",
        "y = torch.cat((y_mnist,y_svhn))\n",
        "#img = X_mnist.__getitem__(0)\n",
        "#img.shape\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "pD6_X84wMUog",
        "outputId": "e4742ebb-197f-4069-a28e-f3f7e93cde40",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([120000, 3, 32, 32])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OLPOVRSQMZPo",
        "colab": {}
      },
      "source": [
        "ds_dataset = torch.utils.data.TensorDataset(X,y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IYnvNuCHMZaN",
        "colab": {}
      },
      "source": [
        "classifier_loader = DataLoader(ds_dataset,\n",
        "                          batch_size=train_batch_size, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Gzet3Yf0M2eX"
      },
      "source": [
        "#### Training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b_NAN-X8AAV3",
        "colab_type": "text"
      },
      "source": [
        "##### Initializing Models\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6uqi8nLn_8MH",
        "colab_type": "code",
        "outputId": "6a6d2203-60ac-4722-ed9c-c6eaa9c3541a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "feature_extractor = FeatureExtractor().cuda()\n",
        "label_predictor = LabelPredictor().cuda()\n",
        "domain_classifier = DomainClassifier().cuda()\n",
        "\n",
        "parameters = [param for param in feature_extractor.parameters()]\n",
        "parameters_domain = [param for param in domain_classifier.parameters()]\n",
        "parameters_classifier = [param for param in label_predictor.parameters()]\n",
        "parameters += (parameters_domain)\n",
        "parameters += (parameters_classifier)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ks_xhE5X03Hb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Testing model\n",
        "def test(feature_extractor, class_predictor, device, test_loader):\n",
        "    feature_extractor.eval()\n",
        "    class_predictor.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            # print(data.shape)\n",
        "            output = class_predictor(feature_extractor(data))\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "       test_loss, correct, len(test_loader.dataset),\n",
        "       100. * correct / len(test_loader.dataset)))\n",
        "    return 100. * correct / len(test_loader.dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JbLOUGuX1Zzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QWhjDOQ1Z6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHPn_wZD1aBz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Zc-nWQggNWPW"
      },
      "source": [
        "###### Training part\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "1ISu4NO_tnzS",
        "outputId": "dd948a5f-451c-4f32-923f-3c5da0643ee0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "# Usage of CUDA\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "#Parameters\n",
        "epoch_num = 200\n",
        "log_interval = 200\n",
        "lambd = 1\n",
        "gamma = 10\n",
        "\n",
        "svhn_test_accuracies = []\n",
        "mnist_test_accuracies = []\n",
        "svhn_train_accuracies = []\n",
        "total_steps = epoch_num * len(train_loader)\n",
        "\n",
        "optimizer = optim.Adam(parameters)\n",
        "new_optimizer = optim.SGD(parameters,lr=0.01, momentum=0.9)\n",
        "for epoch in range(epoch_num):\n",
        "  start_steps = epoch * len(train_loader)\n",
        "  dataloader_iterator = iter(enumerate(mnist_train_loader))\n",
        "  print(\"Epoch num is \", epoch)\n",
        "  feature_extractor.train()\n",
        "  label_predictor.train()\n",
        "  domain_classifier.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      p = float(batch_idx + start_steps) / total_steps\n",
        "      new_lambda = 2. / (1. + np.exp(- gamma * p)) - 1\n",
        "      domain_classifier.set_lambda(new_lambda)\n",
        "      data, target = data.to(device), target.to(device)\n",
        "      for param_group in new_optimizer.param_groups:\n",
        "       param_group['lr'] = 0.01 / (1. + 10 * p) ** 0.75\n",
        "      new_optimizer.zero_grad()\n",
        "      # print(data.shape)\n",
        "      y_svhn = torch.ones(len(data))\n",
        "      \n",
        "      features = feature_extractor(data)\n",
        "      features = features.to(device)\n",
        "      output = label_predictor(features)\n",
        "      output_source = domain_classifier(features)\n",
        "      #print(output) \n",
        "      #print(output.shape)\n",
        "      #print(target.shape)\n",
        "      loss = F.nll_loss(output, target)\n",
        "      loss.backward(retain_graph=True)\n",
        "      #predictor_optimizer.step()\n",
        "      if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                  100. * batch_idx / len(train_loader), loss.item()))\n",
        "      try:\n",
        "        d_batch_idx, (d_data, d_target) = next(dataloader_iterator)\n",
        "      except StopIteration:\n",
        "            dataloader_iterator = iter(enumerate(mnist_train_loader))\n",
        "            d_batch_idx, (d_data, d_target) = next(dataloader_iterator)\n",
        "      data, target = d_data.to(device), d_target.to(device)\n",
        "      y_mnist = torch.zeros(len(data))\n",
        "      #classifier_optimizer.zero_grad()\n",
        "      # print(data.shape)\n",
        "      features = feature_extractor(data)\n",
        "      features = features.to(device)\n",
        "      output = domain_classifier(features) \n",
        "      # print(output.shape)\n",
        "      #print(output)\n",
        "      #print(target)\n",
        "      criterion = nn.CrossEntropyLoss()\n",
        "      loss = criterion(output, y_mnist.long().to(device)) * lambd + criterion(output_source, y_svhn.long().to(device)) * lambd\n",
        "      loss.backward()\n",
        "      new_optimizer.step()\n",
        "      if batch_idx % log_interval == 0:\n",
        "          print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "              epoch, batch_idx * len(data), len(mnist_train_loader.dataset),\n",
        "                  100. * batch_idx / len(mnist_train_loader), loss.item()))\n",
        "  print(\"Accuracy on SVHN test:\")\n",
        "  svhn_test_accuracies.append(test(feature_extractor, label_predictor, device, svhn_test_loader))\n",
        "  print(\"Accuracy on MNIST test:\")\n",
        "  mnist_test_accuracies.append(test(feature_extractor, label_predictor, device, mnist_test_loader))\n",
        "  print(\"Accuracy on SVHN train:\")\n",
        "  svhn_train_accuracies.append(test(feature_extractor, label_predictor, device, svhn_train_loader))\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch num is  0\n",
            "Train Epoch: 0 [0/73257 (0%)]\tLoss: 2.310196\n",
            "Train Epoch: 0 [0/60000 (0%)]\tLoss: 1.389425\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 0 [12800/73257 (17%)]\tLoss: 1.882573\n",
            "Train Epoch: 0 [12800/60000 (21%)]\tLoss: 0.003443\n",
            "Train Epoch: 0 [25600/73257 (35%)]\tLoss: 0.784596\n",
            "Train Epoch: 0 [25600/60000 (43%)]\tLoss: 0.719676\n",
            "Train Epoch: 0 [38400/73257 (52%)]\tLoss: 0.493824\n",
            "Train Epoch: 0 [38400/60000 (64%)]\tLoss: 0.711382\n",
            "Train Epoch: 0 [51200/73257 (70%)]\tLoss: 0.467576\n",
            "Train Epoch: 0 [51200/60000 (85%)]\tLoss: 0.768076\n",
            "Train Epoch: 0 [64000/73257 (87%)]\tLoss: 0.586269\n",
            "Train Epoch: 0 [64000/60000 (107%)]\tLoss: 0.713442\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4287, Accuracy: 22716/26032 (87.26%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.3318, Accuracy: 5915/10000 (59.15%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.3774, Accuracy: 65029/73257 (88.77%)\n",
            "\n",
            "Epoch num is  1\n",
            "Train Epoch: 1 [0/73257 (0%)]\tLoss: 0.377133\n",
            "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.724585\n",
            "Train Epoch: 1 [12800/73257 (17%)]\tLoss: 0.494736\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.733836\n",
            "Train Epoch: 1 [25600/73257 (35%)]\tLoss: 0.377842\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.732191\n",
            "Train Epoch: 1 [38400/73257 (52%)]\tLoss: 0.270311\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.726933\n",
            "Train Epoch: 1 [51200/73257 (70%)]\tLoss: 0.235429\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.094918\n",
            "Train Epoch: 1 [64000/73257 (87%)]\tLoss: 0.318577\n",
            "Train Epoch: 1 [64000/60000 (107%)]\tLoss: 0.139191\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3135, Accuracy: 23666/26032 (90.91%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.6447, Accuracy: 6790/10000 (67.90%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.2583, Accuracy: 67715/73257 (92.43%)\n",
            "\n",
            "Epoch num is  2\n",
            "Train Epoch: 2 [0/73257 (0%)]\tLoss: 0.140399\n",
            "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.091737\n",
            "Train Epoch: 2 [12800/73257 (17%)]\tLoss: 0.313898\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.178604\n",
            "Train Epoch: 2 [25600/73257 (35%)]\tLoss: 0.318437\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.403266\n",
            "Train Epoch: 2 [38400/73257 (52%)]\tLoss: 0.235832\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.575587\n",
            "Train Epoch: 2 [51200/73257 (70%)]\tLoss: 0.294855\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.618019\n",
            "Train Epoch: 2 [64000/73257 (87%)]\tLoss: 0.313930\n",
            "Train Epoch: 2 [64000/60000 (107%)]\tLoss: 0.936390\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3355, Accuracy: 23482/26032 (90.20%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.4014, Accuracy: 6381/10000 (63.81%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.2682, Accuracy: 67377/73257 (91.97%)\n",
            "\n",
            "Epoch num is  3\n",
            "Train Epoch: 3 [0/73257 (0%)]\tLoss: 0.162483\n",
            "Train Epoch: 3 [0/60000 (0%)]\tLoss: 1.070489\n",
            "Train Epoch: 3 [12800/73257 (17%)]\tLoss: 0.162168\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.954961\n",
            "Train Epoch: 3 [25600/73257 (35%)]\tLoss: 0.364476\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 1.197570\n",
            "Train Epoch: 3 [38400/73257 (52%)]\tLoss: 0.344761\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.893644\n",
            "Train Epoch: 3 [51200/73257 (70%)]\tLoss: 0.195536\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 1.061966\n",
            "Train Epoch: 3 [64000/73257 (87%)]\tLoss: 0.233925\n",
            "Train Epoch: 3 [64000/60000 (107%)]\tLoss: 1.256432\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3177, Accuracy: 23602/26032 (90.67%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.2117, Accuracy: 6899/10000 (68.99%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.2273, Accuracy: 68376/73257 (93.34%)\n",
            "\n",
            "Epoch num is  4\n",
            "Train Epoch: 4 [0/73257 (0%)]\tLoss: 0.328525\n",
            "Train Epoch: 4 [0/60000 (0%)]\tLoss: 1.308662\n",
            "Train Epoch: 4 [12800/73257 (17%)]\tLoss: 0.198746\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 1.167819\n",
            "Train Epoch: 4 [25600/73257 (35%)]\tLoss: 0.260178\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 1.266392\n",
            "Train Epoch: 4 [38400/73257 (52%)]\tLoss: 0.089571\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 1.347120\n",
            "Train Epoch: 4 [51200/73257 (70%)]\tLoss: 0.107955\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 1.155229\n",
            "Train Epoch: 4 [64000/73257 (87%)]\tLoss: 0.140456\n",
            "Train Epoch: 4 [64000/60000 (107%)]\tLoss: 1.299778\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3200, Accuracy: 23688/26032 (91.00%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.1188, Accuracy: 7406/10000 (74.06%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.2119, Accuracy: 68594/73257 (93.63%)\n",
            "\n",
            "Epoch num is  5\n",
            "Train Epoch: 5 [0/73257 (0%)]\tLoss: 0.211516\n",
            "Train Epoch: 5 [0/60000 (0%)]\tLoss: 1.389055\n",
            "Train Epoch: 5 [12800/73257 (17%)]\tLoss: 0.192988\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 1.382680\n",
            "Train Epoch: 5 [25600/73257 (35%)]\tLoss: 0.333393\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 1.337527\n",
            "Train Epoch: 5 [38400/73257 (52%)]\tLoss: 0.070971\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 1.270804\n",
            "Train Epoch: 5 [51200/73257 (70%)]\tLoss: 0.278479\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 1.248883\n",
            "Train Epoch: 5 [64000/73257 (87%)]\tLoss: 0.150786\n",
            "Train Epoch: 5 [64000/60000 (107%)]\tLoss: 1.171672\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3008, Accuracy: 23950/26032 (92.00%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.1531, Accuracy: 7532/10000 (75.32%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.1619, Accuracy: 69674/73257 (95.11%)\n",
            "\n",
            "Epoch num is  6\n",
            "Train Epoch: 6 [0/73257 (0%)]\tLoss: 0.206704\n",
            "Train Epoch: 6 [0/60000 (0%)]\tLoss: 1.356266\n",
            "Train Epoch: 6 [12800/73257 (17%)]\tLoss: 0.269755\n",
            "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 1.420419\n",
            "Train Epoch: 6 [25600/73257 (35%)]\tLoss: 0.098620\n",
            "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 1.286042\n",
            "Train Epoch: 6 [38400/73257 (52%)]\tLoss: 0.180399\n",
            "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 1.317242\n",
            "Train Epoch: 6 [51200/73257 (70%)]\tLoss: 0.147752\n",
            "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 1.262360\n",
            "Train Epoch: 6 [64000/73257 (87%)]\tLoss: 0.108613\n",
            "Train Epoch: 6 [64000/60000 (107%)]\tLoss: 1.507962\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.2956, Accuracy: 23959/26032 (92.04%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 0.8317, Accuracy: 8169/10000 (81.69%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.1406, Accuracy: 70364/73257 (96.05%)\n",
            "\n",
            "Epoch num is  7\n",
            "Train Epoch: 7 [0/73257 (0%)]\tLoss: 0.122559\n",
            "Train Epoch: 7 [0/60000 (0%)]\tLoss: 1.400936\n",
            "Train Epoch: 7 [12800/73257 (17%)]\tLoss: 0.195914\n",
            "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 1.288285\n",
            "Train Epoch: 7 [25600/73257 (35%)]\tLoss: 0.067387\n",
            "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 1.365775\n",
            "Train Epoch: 7 [38400/73257 (52%)]\tLoss: 0.132503\n",
            "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 1.180799\n",
            "Train Epoch: 7 [51200/73257 (70%)]\tLoss: 0.134786\n",
            "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 1.375233\n",
            "Train Epoch: 7 [64000/73257 (87%)]\tLoss: 0.099140\n",
            "Train Epoch: 7 [64000/60000 (107%)]\tLoss: 1.157017\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.2802, Accuracy: 24035/26032 (92.33%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 0.9799, Accuracy: 7964/10000 (79.64%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.1363, Accuracy: 70346/73257 (96.03%)\n",
            "\n",
            "Epoch num is  8\n",
            "Train Epoch: 8 [0/73257 (0%)]\tLoss: 0.155339\n",
            "Train Epoch: 8 [0/60000 (0%)]\tLoss: 1.388667\n",
            "Train Epoch: 8 [12800/73257 (17%)]\tLoss: 0.113036\n",
            "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 1.382650\n",
            "Train Epoch: 8 [25600/73257 (35%)]\tLoss: 0.214498\n",
            "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 1.256678\n",
            "Train Epoch: 8 [38400/73257 (52%)]\tLoss: 0.156437\n",
            "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 1.326993\n",
            "Train Epoch: 8 [51200/73257 (70%)]\tLoss: 0.079591\n",
            "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 1.252443\n",
            "Train Epoch: 8 [64000/73257 (87%)]\tLoss: 0.207293\n",
            "Train Epoch: 8 [64000/60000 (107%)]\tLoss: 1.373377\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.2815, Accuracy: 24147/26032 (92.76%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.1765, Accuracy: 7877/10000 (78.77%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0974, Accuracy: 71174/73257 (97.16%)\n",
            "\n",
            "Epoch num is  9\n",
            "Train Epoch: 9 [0/73257 (0%)]\tLoss: 0.031394\n",
            "Train Epoch: 9 [0/60000 (0%)]\tLoss: 1.340399\n",
            "Train Epoch: 9 [12800/73257 (17%)]\tLoss: 0.054677\n",
            "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 1.380624\n",
            "Train Epoch: 9 [25600/73257 (35%)]\tLoss: 0.037394\n",
            "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 1.245885\n",
            "Train Epoch: 9 [38400/73257 (52%)]\tLoss: 0.163771\n",
            "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 1.158183\n",
            "Train Epoch: 9 [51200/73257 (70%)]\tLoss: 0.086530\n",
            "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 1.172490\n",
            "Train Epoch: 9 [64000/73257 (87%)]\tLoss: 0.174781\n",
            "Train Epoch: 9 [64000/60000 (107%)]\tLoss: 1.476689\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.2896, Accuracy: 24071/26032 (92.47%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.3149, Accuracy: 7619/10000 (76.19%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.1020, Accuracy: 71031/73257 (96.96%)\n",
            "\n",
            "Epoch num is  10\n",
            "Train Epoch: 10 [0/73257 (0%)]\tLoss: 0.136393\n",
            "Train Epoch: 10 [0/60000 (0%)]\tLoss: 1.344860\n",
            "Train Epoch: 10 [12800/73257 (17%)]\tLoss: 0.103782\n",
            "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 1.271137\n",
            "Train Epoch: 10 [25600/73257 (35%)]\tLoss: 0.064831\n",
            "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 1.384722\n",
            "Train Epoch: 10 [38400/73257 (52%)]\tLoss: 0.154188\n",
            "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 1.418204\n",
            "Train Epoch: 10 [51200/73257 (70%)]\tLoss: 0.083982\n",
            "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 1.345210\n",
            "Train Epoch: 10 [64000/73257 (87%)]\tLoss: 0.143608\n",
            "Train Epoch: 10 [64000/60000 (107%)]\tLoss: 1.385182\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3181, Accuracy: 23932/26032 (91.93%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.2992, Accuracy: 7492/10000 (74.92%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0941, Accuracy: 71032/73257 (96.96%)\n",
            "\n",
            "Epoch num is  11\n",
            "Train Epoch: 11 [0/73257 (0%)]\tLoss: 0.085355\n",
            "Train Epoch: 11 [0/60000 (0%)]\tLoss: 1.295610\n",
            "Train Epoch: 11 [12800/73257 (17%)]\tLoss: 0.039344\n",
            "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 1.179541\n",
            "Train Epoch: 11 [25600/73257 (35%)]\tLoss: 0.056509\n",
            "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 1.362137\n",
            "Train Epoch: 11 [38400/73257 (52%)]\tLoss: 0.045718\n",
            "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 1.313842\n",
            "Train Epoch: 11 [51200/73257 (70%)]\tLoss: 0.138407\n",
            "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 1.197101\n",
            "Train Epoch: 11 [64000/73257 (87%)]\tLoss: 0.125235\n",
            "Train Epoch: 11 [64000/60000 (107%)]\tLoss: 1.199117\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3295, Accuracy: 23823/26032 (91.51%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.0859, Accuracy: 7878/10000 (78.78%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0883, Accuracy: 71337/73257 (97.38%)\n",
            "\n",
            "Epoch num is  12\n",
            "Train Epoch: 12 [0/73257 (0%)]\tLoss: 0.062951\n",
            "Train Epoch: 12 [0/60000 (0%)]\tLoss: 1.243201\n",
            "Train Epoch: 12 [12800/73257 (17%)]\tLoss: 0.070096\n",
            "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 1.162710\n",
            "Train Epoch: 12 [25600/73257 (35%)]\tLoss: 0.045021\n",
            "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 1.370234\n",
            "Train Epoch: 12 [38400/73257 (52%)]\tLoss: 0.054030\n",
            "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 1.356306\n",
            "Train Epoch: 12 [51200/73257 (70%)]\tLoss: 0.056657\n",
            "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 1.335304\n",
            "Train Epoch: 12 [64000/73257 (87%)]\tLoss: 0.117298\n",
            "Train Epoch: 12 [64000/60000 (107%)]\tLoss: 1.313264\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3516, Accuracy: 23934/26032 (91.94%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.6355, Accuracy: 7822/10000 (78.22%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0748, Accuracy: 71549/73257 (97.67%)\n",
            "\n",
            "Epoch num is  13\n",
            "Train Epoch: 13 [0/73257 (0%)]\tLoss: 0.146063\n",
            "Train Epoch: 13 [0/60000 (0%)]\tLoss: 1.267215\n",
            "Train Epoch: 13 [12800/73257 (17%)]\tLoss: 0.120675\n",
            "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 1.285264\n",
            "Train Epoch: 13 [25600/73257 (35%)]\tLoss: 0.025043\n",
            "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 1.353705\n",
            "Train Epoch: 13 [38400/73257 (52%)]\tLoss: 0.179244\n",
            "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 1.359254\n",
            "Train Epoch: 13 [51200/73257 (70%)]\tLoss: 0.072904\n",
            "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 1.374815\n",
            "Train Epoch: 13 [64000/73257 (87%)]\tLoss: 0.153739\n",
            "Train Epoch: 13 [64000/60000 (107%)]\tLoss: 1.444309\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3863, Accuracy: 23787/26032 (91.38%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.7283, Accuracy: 6649/10000 (66.49%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0992, Accuracy: 70883/73257 (96.76%)\n",
            "\n",
            "Epoch num is  14\n",
            "Train Epoch: 14 [0/73257 (0%)]\tLoss: 0.072309\n",
            "Train Epoch: 14 [0/60000 (0%)]\tLoss: 1.294888\n",
            "Train Epoch: 14 [12800/73257 (17%)]\tLoss: 0.081012\n",
            "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 1.417631\n",
            "Train Epoch: 14 [25600/73257 (35%)]\tLoss: 0.131221\n",
            "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 1.387698\n",
            "Train Epoch: 14 [38400/73257 (52%)]\tLoss: 0.022022\n",
            "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 1.363055\n",
            "Train Epoch: 14 [51200/73257 (70%)]\tLoss: 0.059636\n",
            "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 1.489432\n",
            "Train Epoch: 14 [64000/73257 (87%)]\tLoss: 0.057698\n",
            "Train Epoch: 14 [64000/60000 (107%)]\tLoss: 1.281991\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3661, Accuracy: 23958/26032 (92.03%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.5890, Accuracy: 7758/10000 (77.58%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0635, Accuracy: 71775/73257 (97.98%)\n",
            "\n",
            "Epoch num is  15\n",
            "Train Epoch: 15 [0/73257 (0%)]\tLoss: 0.074315\n",
            "Train Epoch: 15 [0/60000 (0%)]\tLoss: 1.285524\n",
            "Train Epoch: 15 [12800/73257 (17%)]\tLoss: 0.057031\n",
            "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 1.380728\n",
            "Train Epoch: 15 [25600/73257 (35%)]\tLoss: 0.014106\n",
            "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 1.371916\n",
            "Train Epoch: 15 [38400/73257 (52%)]\tLoss: 0.102404\n",
            "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 1.248321\n",
            "Train Epoch: 15 [51200/73257 (70%)]\tLoss: 0.117149\n",
            "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 1.296313\n",
            "Train Epoch: 15 [64000/73257 (87%)]\tLoss: 0.054107\n",
            "Train Epoch: 15 [64000/60000 (107%)]\tLoss: 1.445965\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4193, Accuracy: 23919/26032 (91.88%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.7467, Accuracy: 7652/10000 (76.52%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0543, Accuracy: 71948/73257 (98.21%)\n",
            "\n",
            "Epoch num is  16\n",
            "Train Epoch: 16 [0/73257 (0%)]\tLoss: 0.032995\n",
            "Train Epoch: 16 [0/60000 (0%)]\tLoss: 1.351641\n",
            "Train Epoch: 16 [12800/73257 (17%)]\tLoss: 0.064749\n",
            "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 1.353566\n",
            "Train Epoch: 16 [25600/73257 (35%)]\tLoss: 0.034995\n",
            "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 1.306200\n",
            "Train Epoch: 16 [38400/73257 (52%)]\tLoss: 0.029304\n",
            "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 1.291111\n",
            "Train Epoch: 16 [51200/73257 (70%)]\tLoss: 0.146894\n",
            "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 1.381077\n",
            "Train Epoch: 16 [64000/73257 (87%)]\tLoss: 0.111996\n",
            "Train Epoch: 16 [64000/60000 (107%)]\tLoss: 1.333257\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4346, Accuracy: 23967/26032 (92.07%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.8459, Accuracy: 8001/10000 (80.01%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0502, Accuracy: 72022/73257 (98.31%)\n",
            "\n",
            "Epoch num is  17\n",
            "Train Epoch: 17 [0/73257 (0%)]\tLoss: 0.067872\n",
            "Train Epoch: 17 [0/60000 (0%)]\tLoss: 1.258294\n",
            "Train Epoch: 17 [12800/73257 (17%)]\tLoss: 0.082297\n",
            "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 1.233444\n",
            "Train Epoch: 17 [25600/73257 (35%)]\tLoss: 0.044413\n",
            "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 1.298131\n",
            "Train Epoch: 17 [38400/73257 (52%)]\tLoss: 0.054691\n",
            "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 1.528823\n",
            "Train Epoch: 17 [51200/73257 (70%)]\tLoss: 0.046994\n",
            "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 1.349988\n",
            "Train Epoch: 17 [64000/73257 (87%)]\tLoss: 0.089360\n",
            "Train Epoch: 17 [64000/60000 (107%)]\tLoss: 1.734980\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.3984, Accuracy: 24076/26032 (92.49%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.6464, Accuracy: 8087/10000 (80.87%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 72216/73257 (98.58%)\n",
            "\n",
            "Epoch num is  18\n",
            "Train Epoch: 18 [0/73257 (0%)]\tLoss: 0.035969\n",
            "Train Epoch: 18 [0/60000 (0%)]\tLoss: 1.362199\n",
            "Train Epoch: 18 [12800/73257 (17%)]\tLoss: 0.077660\n",
            "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 1.310679\n",
            "Train Epoch: 18 [25600/73257 (35%)]\tLoss: 0.061672\n",
            "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 1.370310\n",
            "Train Epoch: 18 [38400/73257 (52%)]\tLoss: 0.020797\n",
            "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 1.359467\n",
            "Train Epoch: 18 [51200/73257 (70%)]\tLoss: 0.059911\n",
            "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 1.267230\n",
            "Train Epoch: 18 [64000/73257 (87%)]\tLoss: 0.065102\n",
            "Train Epoch: 18 [64000/60000 (107%)]\tLoss: 1.339677\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4182, Accuracy: 24032/26032 (92.32%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.0272, Accuracy: 7738/10000 (77.38%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0341, Accuracy: 72435/73257 (98.88%)\n",
            "\n",
            "Epoch num is  19\n",
            "Train Epoch: 19 [0/73257 (0%)]\tLoss: 0.001870\n",
            "Train Epoch: 19 [0/60000 (0%)]\tLoss: 1.279212\n",
            "Train Epoch: 19 [12800/73257 (17%)]\tLoss: 0.043296\n",
            "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 1.395865\n",
            "Train Epoch: 19 [25600/73257 (35%)]\tLoss: 0.006600\n",
            "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 1.288171\n",
            "Train Epoch: 19 [38400/73257 (52%)]\tLoss: 0.018434\n",
            "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 1.303444\n",
            "Train Epoch: 19 [51200/73257 (70%)]\tLoss: 0.008569\n",
            "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 1.363349\n",
            "Train Epoch: 19 [64000/73257 (87%)]\tLoss: 0.068208\n",
            "Train Epoch: 19 [64000/60000 (107%)]\tLoss: 1.274581\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4039, Accuracy: 23789/26032 (91.38%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 1.8338, Accuracy: 7564/10000 (75.64%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0616, Accuracy: 71919/73257 (98.17%)\n",
            "\n",
            "Epoch num is  20\n",
            "Train Epoch: 20 [0/73257 (0%)]\tLoss: 0.075411\n",
            "Train Epoch: 20 [0/60000 (0%)]\tLoss: 1.099553\n",
            "Train Epoch: 20 [12800/73257 (17%)]\tLoss: 0.012435\n",
            "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 1.317315\n",
            "Train Epoch: 20 [25600/73257 (35%)]\tLoss: 0.042053\n",
            "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 1.325065\n",
            "Train Epoch: 20 [38400/73257 (52%)]\tLoss: 0.077175\n",
            "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 1.361875\n",
            "Train Epoch: 20 [51200/73257 (70%)]\tLoss: 0.075465\n",
            "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 1.182710\n",
            "Train Epoch: 20 [64000/73257 (87%)]\tLoss: 0.138825\n",
            "Train Epoch: 20 [64000/60000 (107%)]\tLoss: 1.344681\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5137, Accuracy: 23894/26032 (91.79%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.0591, Accuracy: 8074/10000 (80.74%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0553, Accuracy: 71913/73257 (98.17%)\n",
            "\n",
            "Epoch num is  21\n",
            "Train Epoch: 21 [0/73257 (0%)]\tLoss: 0.051325\n",
            "Train Epoch: 21 [0/60000 (0%)]\tLoss: 1.370751\n",
            "Train Epoch: 21 [12800/73257 (17%)]\tLoss: 0.018914\n",
            "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 1.402852\n",
            "Train Epoch: 21 [25600/73257 (35%)]\tLoss: 0.007267\n",
            "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 1.372615\n",
            "Train Epoch: 21 [38400/73257 (52%)]\tLoss: 0.013931\n",
            "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 1.351386\n",
            "Train Epoch: 21 [51200/73257 (70%)]\tLoss: 0.015950\n",
            "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 1.430340\n",
            "Train Epoch: 21 [64000/73257 (87%)]\tLoss: 0.021737\n",
            "Train Epoch: 21 [64000/60000 (107%)]\tLoss: 1.358731\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4531, Accuracy: 24143/26032 (92.74%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.6120, Accuracy: 7826/10000 (78.26%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0183, Accuracy: 72824/73257 (99.41%)\n",
            "\n",
            "Epoch num is  22\n",
            "Train Epoch: 22 [0/73257 (0%)]\tLoss: 0.005514\n",
            "Train Epoch: 22 [0/60000 (0%)]\tLoss: 1.252854\n",
            "Train Epoch: 22 [12800/73257 (17%)]\tLoss: 0.069929\n",
            "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 1.335602\n",
            "Train Epoch: 22 [25600/73257 (35%)]\tLoss: 0.083773\n",
            "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 1.306699\n",
            "Train Epoch: 22 [38400/73257 (52%)]\tLoss: 0.074200\n",
            "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 1.296949\n",
            "Train Epoch: 22 [51200/73257 (70%)]\tLoss: 0.080686\n",
            "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 1.267018\n",
            "Train Epoch: 22 [64000/73257 (87%)]\tLoss: 0.046835\n",
            "Train Epoch: 22 [64000/60000 (107%)]\tLoss: 1.338368\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4647, Accuracy: 24040/26032 (92.35%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.1966, Accuracy: 7958/10000 (79.58%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0294, Accuracy: 72543/73257 (99.03%)\n",
            "\n",
            "Epoch num is  23\n",
            "Train Epoch: 23 [0/73257 (0%)]\tLoss: 0.034306\n",
            "Train Epoch: 23 [0/60000 (0%)]\tLoss: 1.400022\n",
            "Train Epoch: 23 [12800/73257 (17%)]\tLoss: 0.022006\n",
            "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 1.325660\n",
            "Train Epoch: 23 [25600/73257 (35%)]\tLoss: 0.036115\n",
            "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 1.333012\n",
            "Train Epoch: 23 [38400/73257 (52%)]\tLoss: 0.128358\n",
            "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 1.262362\n",
            "Train Epoch: 23 [51200/73257 (70%)]\tLoss: 0.015755\n",
            "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 1.396168\n",
            "Train Epoch: 23 [64000/73257 (87%)]\tLoss: 0.056829\n",
            "Train Epoch: 23 [64000/60000 (107%)]\tLoss: 1.365210\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5005, Accuracy: 23863/26032 (91.67%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.7019, Accuracy: 7654/10000 (76.54%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0474, Accuracy: 72131/73257 (98.46%)\n",
            "\n",
            "Epoch num is  24\n",
            "Train Epoch: 24 [0/73257 (0%)]\tLoss: 0.027784\n",
            "Train Epoch: 24 [0/60000 (0%)]\tLoss: 1.303980\n",
            "Train Epoch: 24 [12800/73257 (17%)]\tLoss: 0.000501\n",
            "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 1.385082\n",
            "Train Epoch: 24 [25600/73257 (35%)]\tLoss: 0.015200\n",
            "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 1.346595\n",
            "Train Epoch: 24 [38400/73257 (52%)]\tLoss: 0.016170\n",
            "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 1.367152\n",
            "Train Epoch: 24 [51200/73257 (70%)]\tLoss: 0.001580\n",
            "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 1.368892\n",
            "Train Epoch: 24 [64000/73257 (87%)]\tLoss: 0.047399\n",
            "Train Epoch: 24 [64000/60000 (107%)]\tLoss: 1.280953\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4842, Accuracy: 23831/26032 (91.55%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.5952, Accuracy: 7802/10000 (78.02%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0447, Accuracy: 72155/73257 (98.50%)\n",
            "\n",
            "Epoch num is  25\n",
            "Train Epoch: 25 [0/73257 (0%)]\tLoss: 0.054700\n",
            "Train Epoch: 25 [0/60000 (0%)]\tLoss: 1.153051\n",
            "Train Epoch: 25 [12800/73257 (17%)]\tLoss: 0.005478\n",
            "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 1.365589\n",
            "Train Epoch: 25 [25600/73257 (35%)]\tLoss: 0.005233\n",
            "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 1.264219\n",
            "Train Epoch: 25 [38400/73257 (52%)]\tLoss: 0.053393\n",
            "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 1.348467\n",
            "Train Epoch: 25 [51200/73257 (70%)]\tLoss: 0.010077\n",
            "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 1.304814\n",
            "Train Epoch: 25 [64000/73257 (87%)]\tLoss: 0.065722\n",
            "Train Epoch: 25 [64000/60000 (107%)]\tLoss: 1.347263\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4819, Accuracy: 23808/26032 (91.46%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.6397, Accuracy: 7715/10000 (77.15%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0479, Accuracy: 72103/73257 (98.42%)\n",
            "\n",
            "Epoch num is  26\n",
            "Train Epoch: 26 [0/73257 (0%)]\tLoss: 0.012766\n",
            "Train Epoch: 26 [0/60000 (0%)]\tLoss: 1.315575\n",
            "Train Epoch: 26 [12800/73257 (17%)]\tLoss: 0.009005\n",
            "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 1.310577\n",
            "Train Epoch: 26 [25600/73257 (35%)]\tLoss: 0.042731\n",
            "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 1.341722\n",
            "Train Epoch: 26 [38400/73257 (52%)]\tLoss: 0.072821\n",
            "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 1.369243\n",
            "Train Epoch: 26 [51200/73257 (70%)]\tLoss: 0.063221\n",
            "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 1.248214\n",
            "Train Epoch: 26 [64000/73257 (87%)]\tLoss: 0.094678\n",
            "Train Epoch: 26 [64000/60000 (107%)]\tLoss: 1.319239\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5709, Accuracy: 23672/26032 (90.93%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.4379, Accuracy: 7603/10000 (76.03%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0813, Accuracy: 71434/73257 (97.51%)\n",
            "\n",
            "Epoch num is  27\n",
            "Train Epoch: 27 [0/73257 (0%)]\tLoss: 0.002719\n",
            "Train Epoch: 27 [0/60000 (0%)]\tLoss: 1.352621\n",
            "Train Epoch: 27 [12800/73257 (17%)]\tLoss: 0.058318\n",
            "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 1.229817\n",
            "Train Epoch: 27 [25600/73257 (35%)]\tLoss: 0.009884\n",
            "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 1.293658\n",
            "Train Epoch: 27 [38400/73257 (52%)]\tLoss: 0.045626\n",
            "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 1.278279\n",
            "Train Epoch: 27 [51200/73257 (70%)]\tLoss: 0.196265\n",
            "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 1.364851\n",
            "Train Epoch: 27 [64000/73257 (87%)]\tLoss: 0.033857\n",
            "Train Epoch: 27 [64000/60000 (107%)]\tLoss: 1.390055\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5400, Accuracy: 24012/26032 (92.24%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.8455, Accuracy: 7971/10000 (79.71%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0361, Accuracy: 72359/73257 (98.77%)\n",
            "\n",
            "Epoch num is  28\n",
            "Train Epoch: 28 [0/73257 (0%)]\tLoss: 0.002122\n",
            "Train Epoch: 28 [0/60000 (0%)]\tLoss: 1.335793\n",
            "Train Epoch: 28 [12800/73257 (17%)]\tLoss: 0.024534\n",
            "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 1.321758\n",
            "Train Epoch: 28 [25600/73257 (35%)]\tLoss: 0.044961\n",
            "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 1.409572\n",
            "Train Epoch: 28 [38400/73257 (52%)]\tLoss: 0.071858\n",
            "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 1.379329\n",
            "Train Epoch: 28 [51200/73257 (70%)]\tLoss: 0.023965\n",
            "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 1.355910\n",
            "Train Epoch: 28 [64000/73257 (87%)]\tLoss: 0.004030\n",
            "Train Epoch: 28 [64000/60000 (107%)]\tLoss: 1.356609\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4895, Accuracy: 23828/26032 (91.53%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.1263, Accuracy: 7811/10000 (78.11%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0533, Accuracy: 71963/73257 (98.23%)\n",
            "\n",
            "Epoch num is  29\n",
            "Train Epoch: 29 [0/73257 (0%)]\tLoss: 0.265014\n",
            "Train Epoch: 29 [0/60000 (0%)]\tLoss: 1.334484\n",
            "Train Epoch: 29 [12800/73257 (17%)]\tLoss: 0.006282\n",
            "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 1.274930\n",
            "Train Epoch: 29 [25600/73257 (35%)]\tLoss: 0.040619\n",
            "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 1.386120\n",
            "Train Epoch: 29 [38400/73257 (52%)]\tLoss: 0.028284\n",
            "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 1.376380\n",
            "Train Epoch: 29 [51200/73257 (70%)]\tLoss: 0.011754\n",
            "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 1.315751\n",
            "Train Epoch: 29 [64000/73257 (87%)]\tLoss: 0.019724\n",
            "Train Epoch: 29 [64000/60000 (107%)]\tLoss: 1.367764\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4829, Accuracy: 23716/26032 (91.10%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.0595, Accuracy: 8019/10000 (80.19%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0563, Accuracy: 71910/73257 (98.16%)\n",
            "\n",
            "Epoch num is  30\n",
            "Train Epoch: 30 [0/73257 (0%)]\tLoss: 0.011111\n",
            "Train Epoch: 30 [0/60000 (0%)]\tLoss: 1.289434\n",
            "Train Epoch: 30 [12800/73257 (17%)]\tLoss: 0.037805\n",
            "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 1.374606\n",
            "Train Epoch: 30 [25600/73257 (35%)]\tLoss: 0.001359\n",
            "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 1.327709\n",
            "Train Epoch: 30 [38400/73257 (52%)]\tLoss: 0.028278\n",
            "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 1.382866\n",
            "Train Epoch: 30 [51200/73257 (70%)]\tLoss: 0.059120\n",
            "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 1.324003\n",
            "Train Epoch: 30 [64000/73257 (87%)]\tLoss: 0.074226\n",
            "Train Epoch: 30 [64000/60000 (107%)]\tLoss: 1.304732\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5415, Accuracy: 23909/26032 (91.84%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.1013, Accuracy: 7483/10000 (74.83%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0428, Accuracy: 72216/73257 (98.58%)\n",
            "\n",
            "Epoch num is  31\n",
            "Train Epoch: 31 [0/73257 (0%)]\tLoss: 0.045824\n",
            "Train Epoch: 31 [0/60000 (0%)]\tLoss: 1.211410\n",
            "Train Epoch: 31 [12800/73257 (17%)]\tLoss: 0.036947\n",
            "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 1.373014\n",
            "Train Epoch: 31 [25600/73257 (35%)]\tLoss: 0.017604\n",
            "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 1.351221\n",
            "Train Epoch: 31 [38400/73257 (52%)]\tLoss: 0.039383\n",
            "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 1.399754\n",
            "Train Epoch: 31 [51200/73257 (70%)]\tLoss: 0.006870\n",
            "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 1.228300\n",
            "Train Epoch: 31 [64000/73257 (87%)]\tLoss: 0.045788\n",
            "Train Epoch: 31 [64000/60000 (107%)]\tLoss: 1.331543\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5466, Accuracy: 23808/26032 (91.46%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.4966, Accuracy: 7974/10000 (79.74%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0264, Accuracy: 72641/73257 (99.16%)\n",
            "\n",
            "Epoch num is  32\n",
            "Train Epoch: 32 [0/73257 (0%)]\tLoss: 0.002086\n",
            "Train Epoch: 32 [0/60000 (0%)]\tLoss: 1.376701\n",
            "Train Epoch: 32 [12800/73257 (17%)]\tLoss: 0.036036\n",
            "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 1.289908\n",
            "Train Epoch: 32 [25600/73257 (35%)]\tLoss: 0.011741\n",
            "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 1.381800\n",
            "Train Epoch: 32 [38400/73257 (52%)]\tLoss: 0.028404\n",
            "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 1.272820\n",
            "Train Epoch: 32 [51200/73257 (70%)]\tLoss: 0.017284\n",
            "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 1.299984\n",
            "Train Epoch: 32 [64000/73257 (87%)]\tLoss: 0.011862\n",
            "Train Epoch: 32 [64000/60000 (107%)]\tLoss: 1.189820\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.4991, Accuracy: 23846/26032 (91.60%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 2.1746, Accuracy: 8275/10000 (82.75%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0436, Accuracy: 72209/73257 (98.57%)\n",
            "\n",
            "Epoch num is  33\n",
            "Train Epoch: 33 [0/73257 (0%)]\tLoss: 0.067107\n",
            "Train Epoch: 33 [0/60000 (0%)]\tLoss: 1.375842\n",
            "Train Epoch: 33 [12800/73257 (17%)]\tLoss: 0.015427\n",
            "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 1.286491\n",
            "Train Epoch: 33 [25600/73257 (35%)]\tLoss: 0.069985\n",
            "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 1.314028\n",
            "Train Epoch: 33 [38400/73257 (52%)]\tLoss: 0.117753\n",
            "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 1.247230\n",
            "Train Epoch: 33 [51200/73257 (70%)]\tLoss: 0.018670\n",
            "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 1.249934\n",
            "Train Epoch: 33 [64000/73257 (87%)]\tLoss: 0.009061\n",
            "Train Epoch: 33 [64000/60000 (107%)]\tLoss: 1.339591\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5652, Accuracy: 23934/26032 (91.94%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.2730, Accuracy: 7799/10000 (77.99%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0300, Accuracy: 72551/73257 (99.04%)\n",
            "\n",
            "Epoch num is  34\n",
            "Train Epoch: 34 [0/73257 (0%)]\tLoss: 0.012818\n",
            "Train Epoch: 34 [0/60000 (0%)]\tLoss: 1.203257\n",
            "Train Epoch: 34 [12800/73257 (17%)]\tLoss: 0.016516\n",
            "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 1.356088\n",
            "Train Epoch: 34 [25600/73257 (35%)]\tLoss: 0.026536\n",
            "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 1.163623\n",
            "Train Epoch: 34 [38400/73257 (52%)]\tLoss: 0.005697\n",
            "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 1.347146\n",
            "Train Epoch: 34 [51200/73257 (70%)]\tLoss: 0.044397\n",
            "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 1.317060\n",
            "Train Epoch: 34 [64000/73257 (87%)]\tLoss: 0.049371\n",
            "Train Epoch: 34 [64000/60000 (107%)]\tLoss: 1.385180\n",
            "Accuracy on SVHN test:\n",
            "\n",
            "Test set: Average loss: 0.5554, Accuracy: 23951/26032 (92.01%)\n",
            "\n",
            "Accuracy on MNIST test:\n",
            "\n",
            "Test set: Average loss: 3.0389, Accuracy: 8092/10000 (80.92%)\n",
            "\n",
            "Accuracy on SVHN train:\n",
            "\n",
            "Test set: Average loss: 0.0214, Accuracy: 72782/73257 (99.35%)\n",
            "\n",
            "Epoch num is  35\n",
            "Train Epoch: 35 [0/73257 (0%)]\tLoss: 0.026150\n",
            "Train Epoch: 35 [0/60000 (0%)]\tLoss: 1.347491\n",
            "Train Epoch: 35 [12800/73257 (17%)]\tLoss: 0.039294\n",
            "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 1.219436\n",
            "Train Epoch: 35 [25600/73257 (35%)]\tLoss: 0.024890\n",
            "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 1.344538\n",
            "Train Epoch: 35 [38400/73257 (52%)]\tLoss: 0.013159\n",
            "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 1.240340\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "X1RwGjmOtn7-",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cDaprFpptn-v",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "buTpz8i9toBW",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uqVtfr4ftoEI",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oV5Ya5npgopf",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iPLhDN5Fgosb",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "uzF1_Ng8govM",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}